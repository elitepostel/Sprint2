{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473ec2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется файл: /home/ubuntu/tweets.txt\n",
      "Загружено 1600498 текстов. Пример:\n",
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "\n",
      "✅ DataLoader’ы созданы корректно.\n",
      "Train: 1280398 | Val: 160050 | Test: 160050\n",
      "\n",
      "Пример батча: форма torch.Size([32, 20])\n",
      "tensor([[ 84819,   1365,     16,  28947,     60,   6229,    425,    157,    263,\n",
      "            269,     28, 717386, 717387,     60,    476,    299,  13845,    179,\n",
      "            438,      0],\n",
      "        [  1086,   1661,    533,   1206,     36,   5403,     44,    335,     30,\n",
      "            247, 232391,   1205,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [ 59072,   3377,    140,     40,   1842,   2931,    132,  15441,    984,\n",
      "             45,   1752,    430,    280,  21749,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [ 21978,     53,   2526,    593,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [     8,    295,      8,    386,  10961,    299,     45,  28280,   3297,\n",
      "            205,      8,    291,    427, 116770,      8,    427, 364139,     89,\n",
      "             40,    862],\n",
      "        [   319,    134,    279,    939,   1177,    799,    149,   3328,     53,\n",
      "           2390,    769,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [394710,    468,     79,     16,   2368,    209,  15314,   3909,    256,\n",
      "            140,     40,   1842,   3909,    141,   2918,  41902,      0,      0,\n",
      "              0,      0],\n",
      "        [    40,     97,     63,    988,   2043,  61757,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [ 59407,    339,   6973,     68,    286,     40,    305,    178,    469,\n",
      "             44,      8,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [120786,    578,   4630,    438,   1003,     60,   3784, 120787,     40,\n",
      "          19564,     74,    438,  22471,     72,     89,   1922,   1156,   1017,\n",
      "           2531,     53],\n",
      "        [  2333,   1880,    415,      6, 207889,     15,     36,    337,    633,\n",
      "            203,    260,   1142,     45,  22654,    350,   3054,      0,      0,\n",
      "              0,      0],\n",
      "        [635894,    279,     16,     74,      8,    338,   1911,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [   383,     68,    725,    827,   2024,  12301,    339,    390,    776,\n",
      "            100,    610,    178,    180,     40,   4250,    166,  20908,     40,\n",
      "            262,      6],\n",
      "        [   108,     10,   1765, 299471,     40,   2715,     53, 740096,     44,\n",
      "              6,    412,     40,    237,     16,   3487,    156,    380,     44,\n",
      "             45,   2043],\n",
      "        [420028,    237,     45,   5292,   9714,   4433,     16,    280,    510,\n",
      "            104,     45,  19641,   4433,   3140,    132,   5908,      0,      0,\n",
      "              0,      0],\n",
      "        [   279,    251,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [ 87568,    573,     20,     45,    720,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [    40,    166,    196,   1761,  20809,   6551,  32388, 553175,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [ 55329,     24,   1154,    104,      6, 634440,  86300,    754,    149,\n",
      "           1254,    104,    283,  32227,   1805,     53,  41779,  86732,      0,\n",
      "              0,      0],\n",
      "        [114595,    469,   1191,    162,    181,  18835,   4181,    104,   1722,\n",
      "           1132,     88,    157,      6,   2592,  12074,    112,   1217,     44,\n",
      "         114596,    212],\n",
      "        [   235,   4651,   4034,     20,     51,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [   198,     16,     53,    715,   1215,   4725,    131,  17036,    415,\n",
      "              6,    931,     16,   4315,    727,     22,   1248,      0,      0,\n",
      "              0,      0],\n",
      "        [  1347,     16,     74,    335,    203,     30,     68,    178,   2236,\n",
      "             16,     50,     16,    272,     16,   2438,     13,   3213,    468,\n",
      "           2734,    642],\n",
      "        [  1510,   2014,     44, 334634,  11362,  54016,    706,    316,     16,\n",
      "           1017,    269,     16,    459,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [  7602,      6,    468,    729,    104,     45,   4932,   4077,    655,\n",
      "             30,   1880,    612,   2487,  41045,  16909,    299,   5710,     44,\n",
      "           1187,     60],\n",
      "        [   338,    156,    279,    260,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [  1215,    911, 254360,     20,   4339,     16,     26,   8385,   5992,\n",
      "           5628,    633,     96,     40,    108,    854,   5992,   1608,    407,\n",
      "              0,      0],\n",
      "        [ 15023,    391,     64,    933,    381,     67,    115,     22,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [  3833,     16,   3815,    793,   1043,  11653,     66,     67,     43,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [749475,     88,    595,     40,    388,    439,     76,    141,      8,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [   209,   3729,   1023,     16,  29302,    104,    230,    283,    960,\n",
      "           4174,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0],\n",
      "        [  1274,     20,    332,   6354,    205,    706,  11622,    838,    710,\n",
      "             18,    803,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#  =======   Этап 1. Подготовка данных  ======== \n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Очищает текст от лишних символов:\n",
    "\n",
    "    - убирает пунктуацию, цифры, спецсимволы\n",
    "\n",
    "    - приводит к нижнему регистру\n",
    "\n",
    "    - удаляет лишние пробелы\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text = re.sub(r\"[^а-яА-ЯёЁa-zA-Z\\s]\", \"\", text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    \"\"\"Простой датасет: хранит закодированные тексты\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, encoded_texts, max_len=50):\n",
    "\n",
    "        self.data = encoded_texts\n",
    "\n",
    "        self.max_len = max_len\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Получаем один текст и дополняем нулями до max_len\n",
    "\n",
    "        x = self.data[idx][:self.max_len]\n",
    "\n",
    "        if len(x) < self.max_len:\n",
    "\n",
    "            x = x + [0] * (self.max_len - len(x))\n",
    "\n",
    "        return torch.tensor(x, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataloaders(data_path=\"data/tweets.txt\", batch_size=32, max_len=20):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Главная функция: готовит данные и возвращает\n",
    "\n",
    "    train_loader, val_loader, test_loader, vocab, inv_vocab.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    BASE_DIR = Path.cwd()\n",
    "\n",
    "    file_path = BASE_DIR / data_path\n",
    "\n",
    "\n",
    "\n",
    "    if not file_path.exists():\n",
    "\n",
    "        raise FileNotFoundError(f\"Dataset file not found: {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Используется файл:\", file_path)\n",
    "\n",
    "\n",
    "\n",
    "    # 1) Загружаем тексты\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        texts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "\n",
    "    if len(texts) == 0:\n",
    "\n",
    "        raise ValueError(\"Файл датасета пуст или не содержит непустых строк.\")\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Загружено {len(texts)} текстов. Пример:\")\n",
    "\n",
    "    print(texts[0])\n",
    "\n",
    "\n",
    "\n",
    "    # 2) Предобработка\n",
    "\n",
    "    clean_texts = [preprocess_text(t) for t in texts]\n",
    "\n",
    "    tokenized = [t.split() for t in clean_texts]\n",
    "\n",
    "\n",
    "\n",
    "    # 3) Сохраняем промежуточные файлы (опционально)\n",
    "\n",
    "    output_dir = BASE_DIR / \"data\"\n",
    "\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "    with open(output_dir / \"clean_texts.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        for line in clean_texts:\n",
    "\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(output_dir / \"tokenized_texts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        json.dump(tokenized, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "    # 4) Создаём словарь (vocab) — локальная переменная внутри функции\n",
    "\n",
    "    word_counts = Counter(word for text in tokenized for word in text)\n",
    "\n",
    "    vocab = {word: i + 2 for i, (word, _) in enumerate(word_counts.items())}\n",
    "\n",
    "    vocab[\"<PAD>\"] = 0\n",
    "\n",
    "    vocab[\"<UNK>\"] = 1\n",
    "\n",
    "    inv_vocab = {i: w for w, i in vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "    with open(output_dir / \"vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "    # 5) Кодируем тексты\n",
    "\n",
    "    def encode(tokens):\n",
    "\n",
    "        return [vocab.get(word, vocab[\"<UNK>\"]) for word in tokens]\n",
    "\n",
    "\n",
    "\n",
    "    encoded_texts = [encode(t) for t in tokenized]\n",
    "\n",
    "\n",
    "\n",
    "    with open(output_dir / \"encoded_texts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        json.dump(encoded_texts, f)\n",
    "\n",
    "\n",
    "\n",
    "    # 6) Делим данные\n",
    "\n",
    "    train_texts, temp_texts = train_test_split(encoded_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "    val_texts, test_texts = train_test_split(temp_texts, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "    # 7) Создаём Dataset’ы\n",
    "\n",
    "    train_dataset = TextDataset(train_texts, max_len=max_len)\n",
    "\n",
    "    val_dataset = TextDataset(val_texts, max_len=max_len)\n",
    "\n",
    "    test_dataset = TextDataset(test_texts, max_len=max_len)\n",
    "\n",
    "\n",
    "\n",
    "    # 8) DataLoader’ы\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n✅ DataLoader’ы созданы корректно.\")\n",
    "\n",
    "    print(f\"Train: {len(train_texts)} | Val: {len(val_texts)} | Test: {len(test_texts)}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Возвращаем в фиксированном порядке\n",
    "\n",
    "    return train_loader, val_loader, test_loader, vocab, inv_vocab\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Быстрая проверка при запуске модуля напрямую\n",
    "\n",
    "    train_loader, val_loader, test_loader, vocab, inv_vocab = prepare_dataloaders()\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        print(f\"\\nПример батча: форма {batch.shape}\")\n",
    "\n",
    "        print(batch)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6dc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===============================\n",
    "\n",
    "#   Этап 2. Модель на основе LSTM\n",
    "\n",
    "# ===============================\n",
    "\n",
    "\n",
    "class LSTMTextModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim=32, hidden_dim=32, num_layers=1):\n",
    "\n",
    "        \"\"\"\n",
    "        vocab_size — размер словаря (количество уникальных токенов)\n",
    "\n",
    "        embed_dim — размер эмбеддинга\n",
    "\n",
    "        hidden_dim — размер скрытого состояния LSTM\n",
    "\n",
    "        num_layers — количество слоёв LSTM\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMTextModel, self).__init__()\n",
    "\n",
    "\n",
    "        # Векторные представления токенов\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "\n",
    "        # Основная рекуррентная часть — LSTM\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "\n",
    "        # Линейный слой для предсказания следующего токена\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, hidden=None):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        input_seq: [batch_size, seq_len] — входная последовательность токенов\n",
    "\n",
    "        hidden: скрытые состояния (если передаются вручную)\n",
    "\n",
    "        Возвращает:\n",
    "\n",
    "            logits — предсказания по всем токенам (до softmax)\n",
    "\n",
    "            hidden — новое скрытое состояние LSTM\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        embedded = self.embedding(input_seq)  # [batch, seq_len, embed_dim]\n",
    "\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)  # [batch, seq_len, hidden_dim]\n",
    "\n",
    "        logits = self.fc(lstm_out)  # [batch, seq_len, vocab_size]\n",
    "\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "\n",
    "    def generate(self, start_seq, next_tokens=10, temperature=1.0, device=\"cpu\"):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Генерация последовательности токенов.\n",
    "\n",
    "        start_seq: список токенов (начальная последовательность)\n",
    "\n",
    "        next_tokens: сколько токенов нужно сгенерировать\n",
    "\n",
    "        temperature: параметр \"температуры\" (чем больше, тем более случайные выборы)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.eval()  # режим генерации (отключаем dropout и тд)\n",
    "\n",
    "        generated = torch.tensor(start_seq, dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "        hidden = None\n",
    "\n",
    "\n",
    "        for _ in range(next_tokens):\n",
    "\n",
    "            logits, hidden = self.forward(generated, hidden)\n",
    "\n",
    "            next_token_logits = logits[:, -1, :] / temperature  # берём последние логиты\n",
    "\n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "\n",
    "            next_token = torch.multinomial(probs, num_samples=1)  # случайный выбор токена\n",
    "\n",
    "            generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "        return generated.squeeze(0).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a4630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется файл: /home/ubuntu/tweets.txt\n",
      "Загружено 1600498 текстов. Пример:\n",
      "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
      "\n",
      "✅ DataLoader’ы созданы корректно.\n",
      "Train: 1280398 | Val: 160050 | Test: 160050\n",
      "\n",
      "易 Эпоха 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обучение: 100%|██████████| 40013/40013 [2:44:26<00:00,  4.06it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя функция потерь (train): 3.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Валидация: 100%|██████████| 5002/5002 [08:40<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Валидация: Loss=3.6165 | ROUGE-1=0.5147 | ROUGE-2=0.3971\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LSTMTextModel.generate() got an unexpected keyword argument 'max_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 222\u001b[0m\n\u001b[1;32m    206\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMTextModel(\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Запуск обучения\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43minv_vocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minv_vocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlstm_text_generator.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    241\u001b[0m \n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Обучение завершено успешно!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Модель обучена и сохранена\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 172\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, vocab, inv_vocab, num_epochs, lr, device, save_path)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# --- Пример автодополнения текста ---\u001b[39;00m\n\u001b[1;32m    170\u001b[0m example_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_loader))[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 172\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mПример автодополнения:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mВход:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([inv_vocab[t\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m example_input[\u001b[38;5;241m0\u001b[39m]]))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: LSTMTextModel.generate() got an unexpected keyword argument 'max_len'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "#  =======   Этап 3. Обучение модели  LSTM  ======== \n",
    "\n",
    "\n",
    "# === Настройка устройства (GPU) ===\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Функция вычисления ROUGE ===\n",
    "\n",
    "def compute_rouge(pred_texts, ref_texts):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Подсчитывает средние ROUGE-1 и ROUGE-2 между предсказанными и эталонными текстами.\n",
    "\n",
    "    Используется для оценки качества текстовой генерации.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\"], use_stemmer=True)\n",
    "\n",
    "    rouge1, rouge2 = [], []\n",
    "\n",
    "\n",
    "\n",
    "    for pred, ref in zip(pred_texts, ref_texts):\n",
    "\n",
    "        scores = scorer.score(ref, pred)\n",
    "\n",
    "        rouge1.append(scores[\"rouge1\"].fmeasure)\n",
    "\n",
    "        rouge2.append(scores[\"rouge2\"].fmeasure)\n",
    "\n",
    "\n",
    "\n",
    "    return sum(rouge1)/len(rouge1), sum(rouge2)/len(rouge2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Основная функция обучения модели ===\n",
    "\n",
    "def train_model(model, train_loader, val_loader, vocab, inv_vocab,\n",
    "\n",
    "                num_epochs=1, lr=0.001, device=\"cpu\", save_path=\"lstm_model.pth\"):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Обучает LSTM-модель на тренировочных данных, оценивает на валидации и сохраняет веса.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n易 Эпоха {epoch+1}/{num_epochs}\")\n",
    "\n",
    "\n",
    "\n",
    "        # --- Цикл обучения ---\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Обучение\"):\n",
    "\n",
    "            # batch — это батч предложений (тензор [batch_size, seq_len])\n",
    "\n",
    "            inputs = batch[:, :-1].to(device)   # всё, кроме последнего токена\n",
    "\n",
    "            targets = batch[:, 1:].to(device)   # всё, кроме первого токена\n",
    "\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "\n",
    "\n",
    "\n",
    "            # Переформатируем для функции потерь: [batch*seq, vocab_size]\n",
    "\n",
    "            loss = criterion(outputs.reshape(-1, len(vocab)), targets.reshape(-1))\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        print(f\"Средняя функция потерь (train): {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        # --- Валидация после каждой эпохи ---\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "\n",
    "        preds_text, refs_text = [], []\n",
    "\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for batch in tqdm(val_loader, desc=\"Валидация\"):\n",
    "\n",
    "                inputs = batch[:, :-1].to(device)\n",
    "\n",
    "                targets = batch[:, 1:].to(device)\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "\n",
    "\n",
    "\n",
    "                loss = criterion(outputs.reshape(-1, len(vocab)), targets.reshape(-1))\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=2)\n",
    "\n",
    "                preds_text += [\" \".join([inv_vocab[t.item()] for t in seq]) for seq in preds]\n",
    "\n",
    "                refs_text += [\" \".join([inv_vocab[t.item()] for t in seq]) for seq in targets]\n",
    "\n",
    "\n",
    "\n",
    "        rouge1, rouge2 = compute_rouge(preds_text, refs_text)\n",
    "\n",
    "        print(f\"Валидация: Loss={val_loss/len(val_loader):.4f} | ROUGE-1={rouge1:.4f} | ROUGE-2={rouge2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        # --- Пример автодополнения текста ---\n",
    "\n",
    "        example_input = next(iter(val_loader))[0:1, :5].to(device)\n",
    "\n",
    "        generated = model.generate(example_input)\n",
    "\n",
    "\n",
    "\n",
    "        print(\"\\nПример автодополнения:\")\n",
    "\n",
    "        print(\"Вход:\", \" \".join([inv_vocab[t.item()] for t in example_input[0]]))\n",
    "\n",
    "        print(\"Сгенерировано:\", \" \".join([inv_vocab[t.item()] for t in generated[0]]))\n",
    "\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "\n",
    "\n",
    "    # === Сохранение модели ===\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(f\"✅ Модель сохранена в {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Точка входа ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Загружаем данные и создаём модель\n",
    "\n",
    "    train_loader, val_loader, test_loader, vocab, inv_vocab = prepare_dataloaders()\n",
    "\n",
    "\n",
    "\n",
    "    model = LSTMTextModel(\n",
    "\n",
    "        vocab_size=len(vocab),\n",
    "\n",
    "        embed_dim=32,\n",
    "\n",
    "        hidden_dim=32,\n",
    "\n",
    "        num_layers=1\n",
    "\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    # Запуск обучения\n",
    "\n",
    "    train_model(\n",
    "\n",
    "        model=model,\n",
    "\n",
    "        train_loader=train_loader,\n",
    "\n",
    "        val_loader=val_loader,\n",
    "\n",
    "        vocab=vocab,\n",
    "\n",
    "        inv_vocab=inv_vocab,\n",
    "\n",
    "        num_epochs=1,\n",
    "\n",
    "        lr=0.001,\n",
    "\n",
    "        device=device,\n",
    "\n",
    "        save_path=\"lstm_text_generator.pth\"\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    print(\" Обучение завершено успешно!\")\n",
    "    print(\"✅ Модель обучена и сохранена\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd471dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),\"lstm_text_generator.pth\")\n",
    "print(\"Модель сохранена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cff231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 1600498 текстов. Берём 500 случайных примеров.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Начинаем генерацию...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 2/500 [00:00<00:59,  8.32it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  1%|          | 3/500 [00:00<01:26,  5.77it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  2%|▏         | 8/500 [00:00<00:39, 12.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  2%|▏         | 12/500 [00:00<00:35, 13.66it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  3%|▎         | 14/500 [00:01<00:57,  8.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  3%|▎         | 17/500 [00:01<00:51,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  4%|▍         | 20/500 [00:02<00:47, 10.11it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  4%|▍         | 22/500 [00:02<00:51,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  5%|▌         | 27/500 [00:02<00:38, 12.36it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  6%|▌         | 31/500 [00:02<00:35, 13.29it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  7%|▋         | 34/500 [00:03<00:36, 12.81it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  7%|▋         | 37/500 [00:03<00:36, 12.57it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  8%|▊         | 39/500 [00:03<00:52,  8.80it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  8%|▊         | 42/500 [00:04<00:47,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  9%|▉         | 44/500 [00:04<00:48,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  9%|▉         | 46/500 [00:04<00:49,  9.11it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|▉         | 48/500 [00:04<00:50,  8.89it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 10%|█         | 51/500 [00:04<00:45,  9.88it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 11%|█         | 53/500 [00:05<00:56,  7.86it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 11%|█         | 55/500 [00:05<00:55,  7.99it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 11%|█         | 56/500 [00:05<01:01,  7.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█▏        | 59/500 [00:06<00:56,  7.81it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 12%|█▏        | 60/500 [00:06<01:04,  6.81it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 13%|█▎        | 67/500 [00:06<00:33, 12.91it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 14%|█▍        | 69/500 [00:07<00:47,  9.11it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 15%|█▍        | 74/500 [00:07<00:35, 11.99it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 15%|█▌        | 76/500 [00:07<00:38, 11.08it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 16%|█▋        | 82/500 [00:07<00:30, 13.67it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 17%|█▋        | 84/500 [00:08<00:36, 11.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 17%|█▋        | 86/500 [00:08<00:38, 10.64it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 88/500 [00:08<00:40, 10.10it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 90/500 [00:08<00:42,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 18%|█▊        | 91/500 [00:09<00:50,  8.09it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 19%|█▉        | 95/500 [00:09<00:37, 10.70it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 20%|██        | 101/500 [00:09<00:26, 14.90it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 21%|██        | 103/500 [00:09<00:30, 13.06it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 22%|██▏       | 109/500 [00:10<00:23, 16.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 23%|██▎       | 117/500 [00:10<00:16, 22.63it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██▍       | 123/500 [00:10<00:16, 22.59it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 25%|██▌       | 126/500 [00:10<00:20, 18.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 26%|██▌       | 131/500 [00:11<00:19, 19.40it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 27%|██▋       | 134/500 [00:11<00:20, 17.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 138/500 [00:11<00:19, 18.30it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 140/500 [00:11<00:23, 15.35it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 28%|██▊       | 142/500 [00:12<00:27, 13.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 29%|██▉       | 146/500 [00:12<00:24, 14.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 31%|███       | 156/500 [00:12<00:15, 22.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 33%|███▎      | 163/500 [00:12<00:13, 25.04it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 33%|███▎      | 166/500 [00:13<00:18, 17.78it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 34%|███▎      | 168/500 [00:13<00:22, 15.08it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 35%|███▍      | 173/500 [00:13<00:20, 15.71it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 35%|███▌      | 175/500 [00:13<00:23, 13.67it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 36%|███▌      | 178/500 [00:14<00:24, 13.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 36%|███▌      | 180/500 [00:14<00:35,  9.02it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 37%|███▋      | 183/500 [00:14<00:32,  9.90it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 37%|███▋      | 185/500 [00:15<00:38,  8.19it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 37%|███▋      | 187/500 [00:15<00:38,  8.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 39%|███▊      | 193/500 [00:15<00:24, 12.44it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 39%|███▉      | 195/500 [00:16<00:29, 10.30it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 39%|███▉      | 197/500 [00:16<00:38,  7.85it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 40%|███▉      | 198/500 [00:16<00:42,  7.03it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 41%|████      | 203/500 [00:17<00:28, 10.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 41%|████      | 205/500 [00:17<00:29,  9.89it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 42%|████▏     | 208/500 [00:17<00:27, 10.67it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 42%|████▏     | 211/500 [00:17<00:26, 10.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 43%|████▎     | 214/500 [00:18<00:25, 11.25it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 43%|████▎     | 216/500 [00:18<00:27, 10.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 44%|████▍     | 220/500 [00:18<00:22, 12.34it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 44%|████▍     | 222/500 [00:18<00:31,  8.69it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 45%|████▌     | 225/500 [00:19<00:28,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 45%|████▌     | 227/500 [00:19<00:32,  8.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 46%|████▌     | 231/500 [00:19<00:25, 10.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 47%|████▋     | 234/500 [00:20<00:23, 11.14it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 48%|████▊     | 239/500 [00:20<00:18, 13.93it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 48%|████▊     | 242/500 [00:20<00:19, 13.10it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 49%|████▉     | 245/500 [00:20<00:19, 12.97it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 51%|█████     | 256/500 [00:20<00:10, 22.59it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 52%|█████▏    | 259/500 [00:21<00:15, 15.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 52%|█████▏    | 261/500 [00:21<00:17, 13.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 53%|█████▎    | 263/500 [00:22<00:24,  9.70it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 53%|█████▎    | 265/500 [00:22<00:24,  9.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 54%|█████▍    | 270/500 [00:22<00:18, 12.32it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 54%|█████▍    | 272/500 [00:23<00:25,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 55%|█████▍    | 274/500 [00:23<00:25,  8.90it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 56%|█████▌    | 278/500 [00:23<00:20, 10.90it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 56%|█████▌    | 280/500 [00:23<00:21, 10.30it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 57%|█████▋    | 285/500 [00:24<00:16, 13.18it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 58%|█████▊    | 289/500 [00:24<00:14, 14.28it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 59%|█████▉    | 294/500 [00:24<00:12, 16.29it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|█████▉    | 298/500 [00:24<00:12, 16.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 60%|██████    | 302/500 [00:25<00:13, 14.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 61%|██████    | 305/500 [00:25<00:13, 14.29it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▏   | 308/500 [00:25<00:13, 13.85it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▏   | 310/500 [00:25<00:16, 11.67it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 62%|██████▏   | 312/500 [00:26<00:17, 10.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 63%|██████▎   | 314/500 [00:26<00:18,  9.92it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▎   | 318/500 [00:26<00:15, 11.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▍   | 320/500 [00:27<00:21,  8.32it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 64%|██████▍   | 321/500 [00:27<00:24,  7.32it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 65%|██████▍   | 323/500 [00:27<00:23,  7.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 65%|██████▌   | 325/500 [00:27<00:22,  7.80it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 66%|██████▌   | 329/500 [00:28<00:16, 10.40it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 68%|██████▊   | 338/500 [00:28<00:08, 18.21it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 68%|██████▊   | 340/500 [00:28<00:10, 15.27it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 69%|██████▉   | 347/500 [00:28<00:07, 19.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 70%|███████   | 350/500 [00:28<00:08, 17.23it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 71%|███████   | 353/500 [00:29<00:08, 18.02it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 71%|███████   | 355/500 [00:29<00:09, 14.79it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 71%|███████▏  | 357/500 [00:29<00:11, 12.87it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 72%|███████▏  | 359/500 [00:29<00:12, 11.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 73%|███████▎  | 364/500 [00:30<00:09, 14.94it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 74%|███████▍  | 369/500 [00:30<00:07, 16.86it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 74%|███████▍  | 371/500 [00:30<00:09, 14.30it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████▍  | 374/500 [00:30<00:09, 13.68it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 75%|███████▌  | 376/500 [00:31<00:13,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 76%|███████▋  | 382/500 [00:31<00:09, 12.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 78%|███████▊  | 390/500 [00:31<00:06, 17.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 78%|███████▊  | 392/500 [00:32<00:07, 15.26it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 79%|███████▉  | 394/500 [00:32<00:07, 13.35it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|███████▉  | 398/500 [00:32<00:07, 14.33it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 80%|████████  | 400/500 [00:32<00:07, 12.62it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 81%|████████  | 403/500 [00:33<00:08, 11.31it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 81%|████████  | 405/500 [00:33<00:08, 10.61it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 81%|████████▏ | 407/500 [00:33<00:09,  9.92it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 82%|████████▏ | 409/500 [00:33<00:09,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 82%|████████▏ | 411/500 [00:34<00:09,  9.20it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 83%|████████▎ | 414/500 [00:34<00:08, 10.30it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 83%|████████▎ | 416/500 [00:34<00:08,  9.74it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 85%|████████▍ | 423/500 [00:34<00:04, 15.70it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 87%|████████▋ | 433/500 [00:34<00:02, 23.69it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████▊ | 439/500 [00:35<00:02, 24.35it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 88%|████████▊ | 442/500 [00:35<00:03, 16.13it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 90%|█████████ | 451/500 [00:35<00:02, 19.88it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 91%|█████████ | 454/500 [00:36<00:03, 14.63it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 91%|█████████▏| 457/500 [00:36<00:03, 14.24it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 92%|█████████▏| 461/500 [00:36<00:02, 15.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 93%|█████████▎| 463/500 [00:37<00:02, 13.71it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 93%|█████████▎| 467/500 [00:37<00:02, 14.65it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 94%|█████████▍| 472/500 [00:37<00:01, 18.15it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 95%|█████████▌| 475/500 [00:38<00:02, 10.08it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 95%|█████████▌| 477/500 [00:38<00:02,  9.76it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 97%|█████████▋| 485/500 [00:38<00:01, 14.39it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 98%|█████████▊| 488/500 [00:38<00:00, 14.03it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 98%|█████████▊| 491/500 [00:39<00:00, 13.72it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 99%|█████████▊| 493/500 [00:39<00:00,  9.78it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      " 99%|█████████▉| 496/500 [00:39<00:00, 10.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "100%|██████████| 500/500 [00:40<00:00, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Метрики ROUGE:\n",
      "rouge1: 0.0503\n",
      "rouge2: 0.0050\n",
      "rougeL: 0.0490\n",
      "rougeLsum: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Этап 4. Оценка DistilGPT-2 на тексте ===\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text: str) -> str:\n",
    "\n",
    "    \"\"\"Очищает текст — только буквы и пробелы, без пунктуации\"\"\"\n",
    "\n",
    "    text = re.sub(r\"[^а-яА-ЯёЁa-zA-Z\\s]\", \"\", text)\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    texts = [t for t in texts if len(t.split()) > 8]\n",
    "\n",
    "    texts = list(set(texts))  # удаляем повторы\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_for_rouge(text):\n",
    "\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_transformer_rouge(\n",
    "\n",
    "    data_path=\"data/tweets.txt\",\n",
    "\n",
    "    num_samples=500,\n",
    "\n",
    "    max_length_factor=1.3,\n",
    "\n",
    "    top_k=50,\n",
    "\n",
    "    temperature=0.8,\n",
    "\n",
    "):\n",
    "\n",
    "    import random, torch, re\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    from transformers import pipeline\n",
    "\n",
    "    import evaluate\n",
    "\n",
    "\n",
    "\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "\n",
    "        texts = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Загружено {len(texts)} текстов. Берём {num_samples} случайных примеров.\")\n",
    "\n",
    "    texts = random.sample(texts, min(num_samples, len(texts)))\n",
    "\n",
    "\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    generator = pipeline(\"text-generation\", model=\"distilgpt2\", device=device)\n",
    "\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "\n",
    "    results = []\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nНачинаем генерацию...\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    for text in tqdm(texts):\n",
    "\n",
    "        words = text.split()\n",
    "\n",
    "        if len(words) < 15:\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        split_idx = int(len(words) * 0.85)\n",
    "\n",
    "        prompt = \" \".join(words[:split_idx])\n",
    "\n",
    "        true_ending = \" \".join(words[split_idx:])\n",
    "\n",
    "\n",
    "\n",
    "        generated_output = generator(\n",
    "\n",
    "            prompt,\n",
    "\n",
    "            max_new_tokens=max(15, int(len(words) * 0.5)),\n",
    "\n",
    "            do_sample=True,\n",
    "\n",
    "            top_k=40,           # немного меньше, чтобы фразы были точнее\n",
    "\n",
    "            top_p=0.9,          # добавляем nucleus sampling\n",
    "\n",
    "            temperature=0.7,    # меньше случайности\n",
    "\n",
    "            repetition_penalty=1.2,  # снижает повторяемость\n",
    "\n",
    "            num_return_sequences=1\n",
    "\n",
    "        )[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "\n",
    "        if generated_output.startswith(prompt):\n",
    "\n",
    "            generated_continuation = generated_output[len(prompt):].strip()\n",
    "\n",
    "        else:\n",
    "\n",
    "            generated_continuation = generated_output\n",
    "\n",
    "\n",
    "\n",
    "        rouge.add(\n",
    "\n",
    "            prediction=clean_for_rouge(generated_continuation),\n",
    "\n",
    "            reference=clean_for_rouge(true_ending)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        results.append({\n",
    "\n",
    "            \"prompt\": prompt,\n",
    "\n",
    "            \"true_ending\": true_ending,\n",
    "\n",
    "            \"generated\": generated_continuation\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "    rouge_result = rouge.compute(use_stemmer=True, use_aggregator=True)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n Метрики ROUGE:\")\n",
    "\n",
    "    for key, value in rouge_result.items():\n",
    "\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    return rouge_result, results\n",
    "\n",
    "\n",
    "\n",
    "# === Запуск ===\n",
    "\n",
    "rouge_result_transformer, examples_transformer = evaluate_transformer_rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103bab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.514700</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DistilGPT-2</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.048962</td>\n",
       "      <td>0.049237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model    rouge1    rouge2    rougeL  rougeLsum\n",
       "0         LSTM  0.514700  0.397100  0.506400        NaN\n",
       "1  DistilGPT-2  0.050341  0.005024  0.048962   0.049237"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Выводы:\n",
      "LSTM показала лучшие метрики, возможно, из-за меньшего переобучения или подбора гиперпараметров.\n",
      "DistilGPT-2 можно улучшить через настройку температуры и длины генерации.\n"
     ]
    }
   ],
   "source": [
    "# === Этап 5. Сравнение моделей и формулирование выводов ===\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Метрики LSTM\n",
    "\n",
    "\n",
    "rouge_result_lstm = {\n",
    "\n",
    "    \"rouge1\": 0.5147,\n",
    "\n",
    "    \"rouge2\": 0.3971,\n",
    "\n",
    "    \"rougeL\": 0.5064,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Объединяем метрики\n",
    "\n",
    "df_compare = pd.DataFrame([\n",
    "\n",
    "    {\"Model\": \"LSTM\", **rouge_result_lstm},\n",
    "\n",
    "    {\"Model\": \"DistilGPT-2\", **rouge_result_transformer},\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "display(df_compare)\n",
    "\n",
    "\n",
    "\n",
    "# Визуализация\n",
    "\n",
    "df_compare.set_index(\"Model\").plot(kind=\"bar\", figsize=(7, 4))\n",
    "\n",
    "plt.title(\"Сравнение метрик ROUGE для двух моделей\")\n",
    "\n",
    "plt.ylabel(\"Значение метрики\")\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# === Формулируем выводы ===\n",
    "\n",
    "print(\"\\n Выводы:\")\n",
    "\n",
    "if df_compare.loc[1, \"rougeL\"] > df_compare.loc[0, \"rougeL\"]:\n",
    "\n",
    "    print(\"DistilGPT-2 показала более высокие значения ROUGE, что говорит о лучшей генерации текста.\")\n",
    "\n",
    "    print(\"Она лучше улавливает контекст и продолжает текст более естественно.\")\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"LSTM показала лучшие метрики, возможно, из-за меньшего переобучения или подбора гиперпараметров.\")\n",
    "\n",
    "    print(\"DistilGPT-2 можно улучшить через настройку температуры и длины генерации.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
